✦ Claro. A continuación, se presenta un análisis enfocado exclusivamente en los resultados del experimento con 4 clases (2 conocidas, 2
  desconocidas).

  ---

  Análisis de Resultados del Experimento con 4 Clases


  El objetivo de este experimento era evaluar el rendimiento de la Memoria Asociativa Entrópica (EAM) al ser entrenada con un subconjunto de
  clases (0 y 1) y probada contra el conjunto completo, que incluye clases nunca antes vistas (2 y 3).

  1. Análisis del Gráfico de Rendimiento (graph_prse_MEAN-english.svg)


  !Gráfico de Precisión y Recall (4 Clases) (/home/Ferny/Repos/quick/runs/graph_prse_MEAN-english.svg)


  Este gráfico muestra las métricas clave de rendimiento de la memoria a través de diferentes tamaños (msize).


   * Precisión (Curva Roja): La precisión se mantiene en un excepcional 100% para casi todos los tamaños de memoria.
       * Interpretación: Este es el resultado más importante. La precisión responde a la pregunta: "De todos los patrones que la memoria dijo
         reconocer, ¿cuántos eran realmente de las clases conocidas (0 o 1)?". Un 100% significa que la memoria es extremadamente fiable.
         Prácticamente no comete falsos positivos; es decir, no confunde una clase desconocida (2 o 3) con una conocida. Si la memoria emite
         una respuesta, podemos confiar en ella.


   * Recall / Exhaustividad (Curva Azul): El recall se estabiliza consistentemente alrededor del 50% para la mayoría de los tamaños de memoria.
       * Interpretación: Este valor, que podría parecer bajo, en realidad representa el éxito del experimento. El recall responde a: "De todas
         las muestras que deberían haberse reconocido (clases 0 y 1), ¿cuántas se recuperaron?". Como el conjunto de prueba contiene un 50% de
         clases conocidas (0, 1) y un 50% de clases desconocidas (2, 3), y la memoria está ignorando correctamente estas últimas, el máximo
         recall posible sobre el conjunto total es del 50%. Este resultado demuestra que la memoria está reconociendo exitosamente el
         subconjunto que aprendió y rechazando el que no.


   * Entropía (Barra de Color Inferior): Muestra cómo la cantidad de información (entropía) almacenada en la memoria aumenta a medida que su
     tamaño (msize) crece, lo cual es un comportamiento esperado.


  2. Análisis de las Matrices de Confusión (memory_confrixes.npy)


  Estas matrices nos dan una visión detallada de las predicciones para cada clase y cada tamaño de memoria.


   * Comportamiento con `msize=1` (Memoria Mínima):


   1     [[    0, 12363, 0, 0],
   2      [    0, 12380, 0, 0],
   3      [    0, 12354, 0, 0],
   4      [    0, 12263, 0, 0]]

      La memoria es demasiado simple y falla en discriminar, colapsando todas las entradas (conocidas y desconocidas) en una sola predicción:
  la clase 1. No es un sistema funcional en este nivel.


   * Comportamiento con `msize=2` (Memoria Pequeña y Funcional):


   1     [[10871,   729,    45,   718],
   2      [  136, 11207,   309,   728],
   3      [   83,  1060, 11102,   109],
   4      [  118,   421,    54, 11670]]

      Aquí vemos un comportamiento mucho más útil. La diagonal principal es fuerte, indicando que cuando se reconoce una clase, tiende a ser
  la correcta. Sin embargo, los valores fuera de la diagonal muestran que la tarea es compleja. Por ejemplo, 1060 muestras de la clase 2
  (desconocida) fueron clasificadas erróneamente como clase 1 (conocida). Esto indica un grado de confusión entre las características de las
  diferentes clases.


   * Tendencia General a Medida que `msize` Aumenta: A medida que el tamaño de la memoria crece, la matriz de confusión muestra un
     comportamiento complejo. En algunos puntos, la confusión entre clases aumenta, mientras que en otros disminuye. Esto subraya que el tamaño
     de la memoria es un hiperparámetro crucial que debe ser ajustado cuidadosamente para encontrar el balance óptimo entre generalización y
     especificidad.


  Conclusiones Finales (Experimento de 4 Clases)


   1. Misión Cumplida: El experimento demuestra exitosamente que la EAM puede distinguir entre datos conocidos y desconocidos. No se "rompe" al
      enfrentarse a la novedad.


   2. Alta Fiabilidad como Característica Principal: La principal fortaleza demostrada es la altísima precisión. El sistema prefiere no emitir
      una respuesta a emitir una incorrecta. Este es un rasgo fundamental para aplicaciones donde los falsos positivos son costosos.


   3. La Complejidad Afecta la Discriminación: Aunque la memoria es fiable, la tarea de separar 4 clases es intrínsecamente más difícil que
      separar 2. Esto se refleja en el "ruido" y los errores de clasificación que se observan fuera de la diagonal principal en las matrices de
      confusión.


   4. El "Punto Dulce" del Tamaño de la Memoria: Los resultados confirman que existe un rango óptimo para el tamaño de la memoria. Demasiado
      pequeño y no discrimina; demasiado grande y puede volverse ineficiente o sobreajustar. La selección de este hiperparámetro es clave para
      el rendimiento.
