2025-07-08 11:49:44.268703: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-07-08 11:49:44.279853: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-07-08 11:49:44.293604: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-07-08 11:49:44.297627: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-07-08 11:49:44.307531: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Working directory: runs
Experimental settings: {Parameters: [0.  0.  0.  0.1]}
Memory size (columns): 256
Preprocessed dataset does not exist.
Loading QuickDraw .npy files...
Loading airplane from data/quick/airplane.npy...
Loading alarm clock from data/quick/alarm clock.npy...
Loading apple from data/quick/apple.npy...
Loading calendar from data/quick/calendar.npy...
123399
Loaded 493596 samples from 4 classes.
Adding 50% noise to data.
................................................................................................... 10000 ................................................................................................... 20000 ................................................................................................... 30000 ................................................................................................... 40000 ................................................................................................... 50000 ................................................................................................... 60000 ................................................................................................... 70000 ................................................................................................... 80000 ................................................................................................... 90000 ................................................................................................... 100000 ................................................................................................... 110000 ................................................................................................... 120000 ................................................................................................... 130000 ................................................................................................... 140000 ................................................................................................... 150000 ................................................................................................... 160000 ................................................................................................... 170000 ................................................................................................... 180000 ................................................................................................... 190000 ................................................................................................... 200000 ................................................................................................... 210000 ................................................................................................... 220000 ................................................................................................... 230000 ................................................................................................... 240000 ................................................................................................... 250000 ................................................................................................... 260000 ................................................................................................... 270000 ................................................................................................... 280000 ................................................................................................... 290000 ................................................................................................... 300000 ................................................................................................... 310000 ................................................................................................... 320000 ................................................................................................... 330000 ................................................................................................... 340000 ................................................................................................... 350000 ................................................................................................... 360000 ................................................................................................... 370000 ................................................................................................... 380000 ................................................................................................... 390000 ................................................................................................... 400000 ................................................................................................... 410000 ................................................................................................... 420000 ................................................................................................... 430000 ................................................................................................... 440000 ................................................................................................... 450000 ................................................................................................... 460000 ................................................................................................... 470000 ................................................................................................... 480000 ................................................................................................... 490000 ...................................2025-07-08 12:01:31.230165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20763 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:61:00.0, compute capability: 8.9
2025-07-08 12:01:31.231546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 20763 MB memory:  -> device: 1, name: NVIDIA L4, pci bus id: 0000:b4:00.0, compute capability: 8.9
/home/fborquez/anaconda3/envs/mem/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
Shuffling data and labels
Saving preprocessed dataset
Delimiting segment of data.
Delimiting segment of data.
Model: "encoder"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_1 (InputLayer)      │ (None, 28, 28, 1)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d (Conv2D)                 │ (None, 28, 28, 16)     │           160 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization             │ (None, 28, 28, 16)     │            64 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_1 (Conv2D)               │ (None, 28, 28, 16)     │         2,320 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_1           │ (None, 28, 28, 16)     │            64 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d (MaxPooling2D)    │ (None, 14, 14, 16)     │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ spatial_dropout2d               │ (None, 14, 14, 16)     │             0 │
│ (SpatialDropout2D)              │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_2 (Conv2D)               │ (None, 14, 14, 32)     │         4,640 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_2           │ (None, 14, 14, 32)     │           128 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_3 (Conv2D)               │ (None, 14, 14, 32)     │         9,248 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_3           │ (None, 14, 14, 32)     │           128 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_1 (MaxPooling2D)  │ (None, 7, 7, 32)       │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ spatial_dropout2d_1             │ (None, 7, 7, 32)       │             0 │
│ (SpatialDropout2D)              │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_4 (Conv2D)               │ (None, 7, 7, 64)       │        18,496 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_4           │ (None, 7, 7, 64)       │           256 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_5 (Conv2D)               │ (None, 7, 7, 64)       │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_5           │ (None, 7, 7, 64)       │           256 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_6 (Conv2D)               │ (None, 7, 7, 64)       │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_6           │ (None, 7, 7, 64)       │           256 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_2 (MaxPooling2D)  │ (None, 4, 4, 64)       │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ spatial_dropout2d_2             │ (None, 4, 4, 64)       │             0 │
│ (SpatialDropout2D)              │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_7 (Conv2D)               │ (None, 4, 4, 128)      │        73,856 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_7           │ (None, 4, 4, 128)      │           512 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_8 (Conv2D)               │ (None, 4, 4, 128)      │       147,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_8           │ (None, 4, 4, 128)      │           512 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_9 (Conv2D)               │ (None, 4, 4, 128)      │       147,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_9           │ (None, 4, 4, 128)      │           512 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_3 (MaxPooling2D)  │ (None, 2, 2, 128)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ spatial_dropout2d_3             │ (None, 2, 2, 128)      │             0 │
│ (SpatialDropout2D)              │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_10 (Conv2D)              │ (None, 2, 2, 256)      │       295,168 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_10          │ (None, 2, 2, 256)      │         1,024 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_11 (Conv2D)              │ (None, 2, 2, 256)      │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_11          │ (None, 2, 2, 256)      │         1,024 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_12 (Conv2D)              │ (None, 2, 2, 256)      │       590,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_12          │ (None, 2, 2, 256)      │         1,024 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_4 (MaxPooling2D)  │ (None, 1, 1, 256)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ spatial_dropout2d_4             │ (None, 1, 1, 256)      │             0 │
│ (SpatialDropout2D)              │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ flatten (Flatten)               │ (None, 256)            │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ encoded (LayerNormalization)    │ (None, 256)            │           512 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 1,959,344 (7.47 MB)
 Trainable params: 1,956,464 (7.46 MB)
 Non-trainable params: 2,880 (11.25 KB)
/home/fborquez/anaconda3/envs/mem/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
Model: "classifier"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_2 (InputLayer)      │ (None, 256)            │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 256)            │        65,792 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout (Dropout)               │ (None, 256)            │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 256)            │        65,792 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_1 (Dropout)             │ (None, 256)            │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ classified (Dense)              │ (None, 4)              │         1,028 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 132,612 (518.02 KB)
 Trainable params: 132,612 (518.02 KB)
 Non-trainable params: 0 (0.00 B)
Model: "decoder"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_3 (InputLayer)      │ (None, 256)            │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_2 (Dense)                 │ (None, 6272)           │     1,611,904 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ reshape (Reshape)               │ (None, 7, 7, 128)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_13 (Conv2D)              │ (None, 7, 7, 256)      │       295,168 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ up_sampling2d (UpSampling2D)    │ (None, 14, 14, 256)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ spatial_dropout2d_5             │ (None, 14, 14, 256)    │             0 │
│ (SpatialDropout2D)              │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_13          │ (None, 14, 14, 256)    │         1,024 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_14 (Conv2D)              │ (None, 14, 14, 128)    │       295,040 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ up_sampling2d_1 (UpSampling2D)  │ (None, 28, 28, 128)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ spatial_dropout2d_6             │ (None, 28, 28, 128)    │             0 │
│ (SpatialDropout2D)              │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_14          │ (None, 28, 28, 128)    │           512 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_15 (Conv2D)              │ (None, 28, 28, 1)      │         1,153 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 2,204,801 (8.41 MB)
 Trainable params: 2,204,033 (8.41 MB)
 Non-trainable params: 768 (3.00 KB)
Model: "functional"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input_layer         │ (None, 28, 28, 1) │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ encoder             │ (None, 256)       │  1,959,344 │ input_layer[0][0] │
│ (Functional)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ classifier          │ (None, 4)         │    132,612 │ encoder[0][0]     │
│ (Functional)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ decoder             │ (None, 28, 28, 1) │  2,204,801 │ encoder[0][0]     │
│ (Functional)        │                   │            │                   │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 4,296,757 (16.39 MB)
 Trainable params: 4,293,109 (16.38 MB)
 Non-trainable params: 3,648 (14.25 KB)
Epoch 1/300
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1751997701.732387 3305186 service.cc:146] XLA service 0x7f6c540037e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1751997701.732446 3305186 service.cc:154]   StreamExecutor device (0): NVIDIA L4, Compute Capability 8.9
I0000 00:00:1751997701.732479 3305186 service.cc:154]   StreamExecutor device (1): NVIDIA L4, Compute Capability 8.9
2025-07-08 12:01:41.919666: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2025-07-08 12:01:42.810522: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90101
I0000 00:00:1751997714.872290 3305186 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Epochs waiting: 0
8638/8638 - 75s - 9ms/step - classifier_accuracy: 0.9034 - classifier_loss: 0.2925 - decoder_loss: 0.0883 - decoder_root_mean_squared_error: 0.2971 - loss: 0.3808 - val_classifier_accuracy: 0.9541 - val_classifier_loss: 0.1586 - val_decoder_loss: 0.0856 - val_decoder_root_mean_squared_error: 0.2925 - val_loss: 0.2441
Epoch 2/300
Epochs waiting: 0
8638/8638 - 37s - 4ms/step - classifier_accuracy: 0.9487 - classifier_loss: 0.1670 - decoder_loss: 0.0842 - decoder_root_mean_squared_error: 0.2902 - loss: 0.2513 - val_classifier_accuracy: 0.9626 - val_classifier_loss: 0.1210 - val_decoder_loss: 0.0814 - val_decoder_root_mean_squared_error: 0.2852 - val_loss: 0.2024
Epoch 3/300
Epochs waiting: 0
8638/8638 - 37s - 4ms/step - classifier_accuracy: 0.9567 - classifier_loss: 0.1416 - decoder_loss: 0.0824 - decoder_root_mean_squared_error: 0.2870 - loss: 0.2240 - val_classifier_accuracy: 0.9653 - val_classifier_loss: 0.1090 - val_decoder_loss: 0.0788 - val_decoder_root_mean_squared_error: 0.2806 - val_loss: 0.1878
Epoch 4/300
Epochs waiting: 0
8638/8638 - 37s - 4ms/step - classifier_accuracy: 0.9602 - classifier_loss: 0.1289 - decoder_loss: 0.0807 - decoder_root_mean_squared_error: 0.2841 - loss: 0.2097 - val_classifier_accuracy: 0.9684 - val_classifier_loss: 0.1106 - val_decoder_loss: 0.0771 - val_decoder_root_mean_squared_error: 0.2776 - val_loss: 0.1877
Epoch 5/300
Epochs waiting: 0
8638/8638 - 37s - 4ms/step - classifier_accuracy: 0.9624 - classifier_loss: 0.1212 - decoder_loss: 0.0793 - decoder_root_mean_squared_error: 0.2815 - loss: 0.2005 - val_classifier_accuracy: 0.9690 - val_classifier_loss: 0.0952 - val_decoder_loss: 0.0754 - val_decoder_root_mean_squared_error: 0.2745 - val_loss: 0.1706
Epoch 6/300
Epochs waiting: 0
8638/8638 - 37s - 4ms/step - classifier_accuracy: 0.9645 - classifier_loss: 0.1146 - decoder_loss: 0.0781 - decoder_root_mean_squared_error: 0.2795 - loss: 0.1927 - val_classifier_accuracy: 0.9703 - val_classifier_loss: 0.1010 - val_decoder_loss: 0.0746 - val_decoder_root_mean_squared_error: 0.2730 - val_loss: 0.1755
Epoch 7/300
Epochs waiting: 0
8638/8638 - 37s - 4ms/step - classifier_accuracy: 0.9657 - classifier_loss: 0.1096 - decoder_loss: 0.0774 - decoder_root_mean_squared_error: 0.2782 - loss: 0.1870 - val_classifier_accuracy: 0.9698 - val_classifier_loss: 0.1035 - val_decoder_loss: 0.0736 - val_decoder_root_mean_squared_error: 0.2713 - val_loss: 0.1771
Epoch 8/300
Epochs waiting: 0
8638/8638 - 37s - 4ms/step - classifier_accuracy: 0.9666 - classifier_loss: 0.1070 - decoder_loss: 0.0767 - decoder_root_mean_squared_error: 0.2769 - loss: 0.1837 - val_classifier_accuracy: 0.9718 - val_classifier_loss: 0.0983 - val_decoder_loss: 0.0728 - val_decoder_root_mean_squared_error: 0.2698 - val_loss: 0.1711
Epoch 9/300
Epochs waiting: 1
8638/8638 - 37s - 4ms/step - classifier_accuracy: 0.9676 - classifier_loss: 0.1026 - decoder_loss: 0.0759 - decoder_root_mean_squared_error: 0.2755 - loss: 0.1785 - val_classifier_accuracy: 0.9709 - val_classifier_loss: 0.1104 - val_decoder_loss: 0.0715 - val_decoder_root_mean_squared_error: 0.2674 - val_loss: 0.1819
Epoch 10/300
Epochs waiting: 0
8638/8638 - 37s - 4ms/step - classifier_accuracy: 0.9682 - classifier_loss: 0.1003 - decoder_loss: 0.0749 - decoder_root_mean_squared_error: 0.2737 - loss: 0.1753 - val_classifier_accuracy: 0.9741 - val_classifier_loss: 0.1001 - val_decoder_loss: 0.0708 - val_decoder_root_mean_squared_error: 0.2660 - val_loss: 0.1708
Epoch 11/300
Epochs waiting: 0
8638/8638 - 37s - 4ms/step - classifier_accuracy: 0.9687 - classifier_loss: 0.0985 - decoder_loss: 0.0743 - decoder_root_mean_squared_error: 0.2726 - loss: 0.1728 - val_classifier_accuracy: 0.9731 - val_classifier_loss: 0.0884 - val_decoder_loss: 0.0705 - val_decoder_root_mean_squared_error: 0.2655 - val_loss: 0.1589
Epoch 12/300
Epochs waiting: 0
8638/8638 - 37s - 4ms/step - classifier_accuracy: 0.9693 - classifier_loss: 0.0978 - decoder_loss: 0.0739 - decoder_root_mean_squared_error: 0.2718 - loss: 0.1717 - val_classifier_accuracy: 0.9740 - val_classifier_loss: 0.0952 - val_decoder_loss: 0.0698 - val_decoder_root_mean_squared_error: 0.2641 - val_loss: 0.1649
Epoch 13/300
Epochs waiting: 0
8638/8638 - 37s - 4ms/step - classifier_accuracy: 0.9702 - classifier_loss: 0.0952 - decoder_loss: 0.0735 - decoder_root_mean_squared_error: 0.2712 - loss: 0.1687 - val_classifier_accuracy: 0.9725 - val_classifier_loss: 0.0979 - val_decoder_loss: 0.0696 - val_decoder_root_mean_squared_error: 0.2638 - val_loss: 0.1675
Epoch 14/300
Epochs waiting: 1
8638/8638 - 37s - 4ms/step - classifier_accuracy: 0.9705 - classifier_loss: 0.0939 - decoder_loss: 0.0731 - decoder_root_mean_squared_error: 0.2704 - loss: 0.1670 - val_classifier_accuracy: 0.9743 - val_classifier_loss: 0.1153 - val_decoder_loss: 0.0692 - val_decoder_root_mean_squared_error: 0.2629 - val_loss: 0.1844
Epoch 15/300
Epochs waiting: 2
8638/8638 - 37s - 4ms/step - classifier_accuracy: 0.9708 - classifier_loss: 0.0924 - decoder_loss: 0.0729 - decoder_root_mean_squared_error: 0.2700 - loss: 0.1653 - val_classifier_accuracy: 0.9742 - val_classifier_loss: 0.0976 - val_decoder_loss: 0.0687 - val_decoder_root_mean_squared_error: 0.2621 - val_loss: 0.1663
Epoch 16/300
Epochs waiting: 3
8638/8638 - 37s - 4ms/step - classifier_accuracy: 0.9709 - classifier_loss: 0.0919 - decoder_loss: 0.0726 - decoder_root_mean_squared_error: 0.2694 - loss: 0.1644 - val_classifier_accuracy: 0.9737 - val_classifier_loss: 0.1202 - val_decoder_loss: 0.0686 - val_decoder_root_mean_squared_error: 0.2618 - val_loss: 0.1887
Epoch 17/300
Epochs waiting: 4
8638/8638 - 37s - 4ms/step - classifier_accuracy: 0.9715 - classifier_loss: 0.0903 - decoder_loss: 0.0723 - decoder_root_mean_squared_error: 0.2689 - loss: 0.1626 - val_classifier_accuracy: 0.9755 - val_classifier_loss: 0.0944 - val_decoder_loss: 0.0683 - val_decoder_root_mean_squared_error: 0.2613 - val_loss: 0.1627
Epoch 18/300
Epochs waiting: 0
8638/8638 - 37s - 4ms/step - classifier_accuracy: 0.9718 - classifier_loss: 0.0891 - decoder_loss: 0.0720 - decoder_root_mean_squared_error: 0.2684 - loss: 0.1611 - val_classifier_accuracy: 0.9735 - val_classifier_loss: 0.0886 - val_decoder_loss: 0.0678 - val_decoder_root_mean_squared_error: 0.2604 - val_loss: 0.1564
Epoch 19/300
Epochs waiting: 1
8638/8638 - 36s - 4ms/step - classifier_accuracy: 0.9716 - classifier_loss: 0.0884 - decoder_loss: 0.0718 - decoder_root_mean_squared_error: 0.2679 - loss: 0.1602 - val_classifier_accuracy: 0.9749 - val_classifier_loss: 0.0992 - val_decoder_loss: 0.0675 - val_decoder_root_mean_squared_error: 0.2597 - val_loss: 0.1666
Epoch 20/300
Epochs waiting: 0
8638/8638 - 36s - 4ms/step - classifier_accuracy: 0.9723 - classifier_loss: 0.0887 - decoder_loss: 0.0716 - decoder_root_mean_squared_error: 0.2675 - loss: 0.1602 - val_classifier_accuracy: 0.9751 - val_classifier_loss: 0.0880 - val_decoder_loss: 0.0672 - val_decoder_root_mean_squared_error: 0.2591 - val_loss: 0.1552
Epoch 21/300
Epochs waiting: 1
8638/8638 - 37s - 4ms/step - classifier_accuracy: 0.9723 - classifier_loss: 0.0864 - decoder_loss: 0.0714 - decoder_root_mean_squared_error: 0.2672 - loss: 0.1578 - val_classifier_accuracy: 0.9754 - val_classifier_loss: 0.1062 - val_decoder_loss: 0.0671 - val_decoder_root_mean_squared_error: 0.2591 - val_loss: 0.1733
Epoch 22/300
Epochs waiting: 2
8638/8638 - 37s - 4ms/step - classifier_accuracy: 0.9724 - classifier_loss: 0.0868 - decoder_loss: 0.0711 - decoder_root_mean_squared_error: 0.2667 - loss: 0.1579 - val_classifier_accuracy: 0.9747 - val_classifier_loss: 0.0959 - val_decoder_loss: 0.0667 - val_decoder_root_mean_squared_error: 0.2582 - val_loss: 0.1626
Epoch 23/300
Epochs waiting: 3
8638/8638 - 37s - 4ms/step - classifier_accuracy: 0.9728 - classifier_loss: 0.0866 - decoder_loss: 0.0709 - decoder_root_mean_squared_error: 0.2662 - loss: 0.1575 - val_classifier_accuracy: 0.9747 - val_classifier_loss: 0.0967 - val_decoder_loss: 0.0665 - val_decoder_root_mean_squared_error: 0.2579 - val_loss: 0.1632
Epoch 24/300
Epochs waiting: 4
8638/8638 - 37s - 4ms/step - classifier_accuracy: 0.9734 - classifier_loss: 0.0849 - decoder_loss: 0.0708 - decoder_root_mean_squared_error: 0.2660 - loss: 0.1557 - val_classifier_accuracy: 0.9751 - val_classifier_loss: 0.0962 - val_decoder_loss: 0.0665 - val_decoder_root_mean_squared_error: 0.2578 - val_loss: 0.1627
Epoch 25/300
Epochs waiting: 5
8638/8638 - 37s - 4ms/step - classifier_accuracy: 0.9732 - classifier_loss: 0.0846 - decoder_loss: 0.0706 - decoder_root_mean_squared_error: 0.2658 - loss: 0.1553 - val_classifier_accuracy: 0.9760 - val_classifier_loss: 0.1037 - val_decoder_loss: 0.0662 - val_decoder_root_mean_squared_error: 0.2573 - val_loss: 0.1699
Epoch 26/300
Epochs waiting: 6
8638/8638 - 37s - 4ms/step - classifier_accuracy: 0.9735 - classifier_loss: 0.0841 - decoder_loss: 0.0704 - decoder_root_mean_squared_error: 0.2654 - loss: 0.1545 - val_classifier_accuracy: 0.9762 - val_classifier_loss: 0.1090 - val_decoder_loss: 0.0659 - val_decoder_root_mean_squared_error: 0.2567 - val_loss: 0.1749
Epoch 27/300
Epochs waiting: 7
Restoring model weights from the end of the best epoch.
8638/8638 - 37s - 4ms/step - classifier_accuracy: 0.9736 - classifier_loss: 0.0841 - decoder_loss: 0.0703 - decoder_root_mean_squared_error: 0.2652 - loss: 0.1544 - val_classifier_accuracy: 0.9749 - val_classifier_loss: 0.1243 - val_decoder_loss: 0.0658 - val_decoder_root_mean_squared_error: 0.2565 - val_loss: 0.1901
Epoch 00027: early stopping
[1m   1/1543[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m39:57[0m 2s/step - accuracy: 1.0000 - loss: 0.0277[1m  52/1543[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m1s[0m 996us/step - accuracy: 0.9723 - loss: 0.1140[1m  53/1543[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m1s[0m 1000us/step - accuracy: 0.9724 - loss: 0.1142[1m 107/1543[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m1s[0m 965us/step - accuracy: 0.9739 - loss: 0.1130 [1m 108/1543[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m1s[0m 966us/step - accuracy: 0.9739 - loss: 0.1129[1m 109/1543[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m1s[0m 965us/step - accuracy: 0.9740 - loss: 0.1128[1m 165/1543[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m1s[0m 945us/step - accuracy: 0.9751 - loss: 0.1062[1m 166/1543[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m1s[0m 945us/step - accuracy: 0.9751 - loss: 0.1061[1m 221/1543[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m1s[0m 939us/step - accuracy: 0.9754 - loss: 0.1027[1m 276/1543[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m1s[0m 936us/step - accuracy: 0.9759 - loss: 0.0993[1m 331/1543[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m1s[0m 933us/step - accuracy: 0.9761 - loss: 0.0966[1m 332/1543[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m1s[0m 933us/step - accuracy: 0.9761 - loss: 0.0965[1m 387/1543[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m1s[0m 932us/step - accuracy: 0.9763 - loss: 0.0951[1m 388/1543[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m1s[0m 932us/step - accuracy: 0.9763 - loss: 0.0951[1m 444/1543[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m1s[0m 928us/step - accuracy: 0.9764 - loss: 0.0942[1m 499/1543[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m0s[0m 927us/step - accuracy: 0.9765 - loss: 0.0931[1m 554/1543[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m0s[0m 926us/step - accuracy: 0.9765 - loss: 0.0922[1m 555/1543[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m0s[0m 926us/step - accuracy: 0.9765 - loss: 0.0922[1m 609/1543[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m0s[0m 926us/step - accuracy: 0.9766 - loss: 0.0915[1m 610/1543[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m0s[0m 927us/step - accuracy: 0.9766 - loss: 0.0915[1m 665/1543[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m0s[0m 926us/step - accuracy: 0.9766 - loss: 0.0907[1m 720/1543[0m [32m━━━━━━━━━[0m[37m━━━━━━━━━━━[0m [1m0s[0m 925us/step - accuracy: 0.9767 - loss: 0.0900[1m 775/1543[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 925us/step - accuracy: 0.9767 - loss: 0.0893[1m 776/1543[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 925us/step - accuracy: 0.9767 - loss: 0.0893[1m 831/1543[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 924us/step - accuracy: 0.9767 - loss: 0.0887[1m 886/1543[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m0s[0m 924us/step - accuracy: 0.9767 - loss: 0.0882[1m 942/1543[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m0s[0m 922us/step - accuracy: 0.9767 - loss: 0.0878[1m 943/1543[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m0s[0m 922us/step - accuracy: 0.9767 - loss: 0.0877[1m 998/1543[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m0s[0m 921us/step - accuracy: 0.9767 - loss: 0.0874[1m1053/1543[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m0s[0m 922us/step - accuracy: 0.9767 - loss: 0.0870[1m1108/1543[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m0s[0m 922us/step - accuracy: 0.9767 - loss: 0.0867[1m1162/1543[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 922us/step - accuracy: 0.9767 - loss: 0.0865[1m1163/1543[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 922us/step - accuracy: 0.9767 - loss: 0.0865[1m1218/1543[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 922us/step - accuracy: 0.9767 - loss: 0.0863[1m1274/1543[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 921us/step - accuracy: 0.9767 - loss: 0.0862[1m1275/1543[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 922us/step - accuracy: 0.9767 - loss: 0.0862[1m1329/1543[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 922us/step - accuracy: 0.9767 - loss: 0.0861[1m1385/1543[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 921us/step - accuracy: 0.9767 - loss: 0.0860[1m1386/1543[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 921us/step - accuracy: 0.9767 - loss: 0.0860[1m1441/1543[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 921us/step - accuracy: 0.9767 - loss: 0.0859[1m1496/1543[0m [32m━━━━━━━━━━━━━━━━━━━[0m[37m━[0m [1m0s[0m 921us/step - accuracy: 0.9767 - loss: 0.0859[1m1543/1543[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 1ms/step - accuracy: 0.9767 - loss: 0.0858  [1m1543/1543[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m4s[0m 1ms/step - accuracy: 0.9767 - loss: 0.0858
[1m   1/1543[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m23:25[0m 912ms/step[1m  51/1543[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m1s[0m 1ms/step     [1m 105/1543[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m1s[0m 974us/step[1m 159/1543[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m1s[0m 959us/step[1m 213/1543[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m1s[0m 954us/step[1m 267/1543[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m1s[0m 951us/step[1m 272/1543[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m2s[0m 2ms/step  [1m 323/1543[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m1s[0m 2ms/step[1m 376/1543[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m1s[0m 1ms/step[1m 428/1543[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m1s[0m 1ms/step[1m 482/1543[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m1s[0m 1ms/step[1m 537/1543[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m1s[0m 1ms/step[1m 592/1543[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m1s[0m 1ms/step[1m 645/1543[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m1s[0m 1ms/step[1m 699/1543[0m [32m━━━━━━━━━[0m[37m━━━━━━━━━━━[0m [1m1s[0m 1ms/step[1m 754/1543[0m [32m━━━━━━━━━[0m[37m━━━━━━━━━━━[0m [1m0s[0m 1ms/step[1m 809/1543[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 1ms/step[1m 862/1543[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m0s[0m 1ms/step[1m 915/1543[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m0s[0m 1ms/step[1m 971/1543[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m0s[0m 1ms/step[1m1025/1543[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m0s[0m 1ms/step[1m1079/1543[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m0s[0m 1ms/step[1m1135/1543[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m0s[0m 1ms/step[1m1186/1543[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 1ms/step[1m1240/1543[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 1ms/step[1m1294/1543[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 1ms/step[1m1348/1543[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 1ms/step[1m1404/1543[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 1ms/step[1m1460/1543[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 1ms/step[1m1515/1543[0m [32m━━━━━━━━━━━━━━━━━━━[0m[37m━[0m [1m0s[0m 1ms/step[1m1543/1543[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 2ms/step[1m1543/1543[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m3s[0m 2ms/step
[1m   1/1543[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m26:38[0m 1s/step - loss: 0.0317 - root_mean_squared_error: 0.2564[1m  43/1543[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m1s[0m 1ms/step - loss: 0.0336 - root_mean_squared_error: 0.2565  [1m  44/1543[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m1s[0m 1ms/step - loss: 0.0336 - root_mean_squared_error: 0.2565[1m  91/1543[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m1s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2565[1m  92/1543[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m1s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2565[1m 138/1543[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m1s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2565[1m 139/1543[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m1s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2565[1m 185/1543[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m1s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2565[1m 186/1543[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m1s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2565[1m 232/1543[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m1s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2566[1m 233/1543[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m1s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2566[1m 279/1543[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m1s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2566[1m 280/1543[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m1s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2566[1m 326/1543[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m1s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2566[1m 327/1543[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m1s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2566[1m 373/1543[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m1s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2566[1m 374/1543[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m1s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2566[1m 420/1543[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m1s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2566[1m 421/1543[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m1s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2566[1m 468/1543[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m1s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2567[1m 469/1543[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m1s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2567[1m 514/1543[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m1s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2567[1m 515/1543[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m1s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2567[1m 562/1543[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m1s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2567[1m 563/1543[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m1s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2567[1m 610/1543[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m1s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2567[1m 657/1543[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2567[1m 658/1543[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2567[1m 703/1543[0m [32m━━━━━━━━━[0m[37m━━━━━━━━━━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2568[1m 704/1543[0m [32m━━━━━━━━━[0m[37m━━━━━━━━━━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2568[1m 750/1543[0m [32m━━━━━━━━━[0m[37m━━━━━━━━━━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2568[1m 751/1543[0m [32m━━━━━━━━━[0m[37m━━━━━━━━━━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2568[1m 797/1543[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2568[1m 798/1543[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2568[1m 845/1543[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2568[1m 846/1543[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2568[1m 892/1543[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2569[1m 893/1543[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2569[1m 939/1543[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2569[1m 986/1543[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2569[1m 987/1543[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2569[1m1033/1543[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2569[1m1034/1543[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2569[1m1080/1543[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2569[1m1081/1543[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2569[1m1128/1543[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2570[1m1129/1543[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2570[1m1175/1543[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2570[1m1176/1543[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2570[1m1222/1543[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2570[1m1223/1543[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2570[1m1270/1543[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2570[1m1271/1543[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2570[1m1317/1543[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2570[1m1318/1543[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2570[1m1365/1543[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2570[1m1366/1543[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2570[1m1413/1543[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2571[1m1414/1543[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2571[1m1459/1543[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2571[1m1460/1543[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2571[1m1509/1543[0m [32m━━━━━━━━━━━━━━━━━━━[0m[37m━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2571[1m1510/1543[0m [32m━━━━━━━━━━━━━━━━━━━[0m[37m━[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2571[1m1543/1543[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2571[1m1543/1543[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m3s[0m 1ms/step - loss: 0.0335 - root_mean_squared_error: 0.2571
